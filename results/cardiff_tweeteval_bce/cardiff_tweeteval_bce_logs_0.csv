epoch,val_loss,step,train_loss
0,0.698638916015625,5,
0,,5,0.6973775029182434
1,0.687896728515625,11,
1,,11,0.6902669072151184
2,0.663238525390625,17,
2,,17,0.670867919921875
3,0.634735107421875,23,
3,,23,0.6301472783088684
4,0.596893310546875,29,
4,,29,0.5904032588005066
5,0.578399658203125,35,
5,,35,0.5442555546760559
6,0.55804443359375,41,
6,,41,0.52105712890625
7,0.55487060546875,47,
7,,47,0.4882761538028717
8,0.550567626953125,53,
8,,53,0.4655914306640625
9,0.545806884765625,59,
9,,59,0.4370218813419342
10,0.54925537109375,65,
10,,65,0.42034912109375
11,0.5464630126953125,71,
11,,71,0.4069162905216217
12,0.5448150634765625,77,
12,,77,0.3996073305606842
13,0.548553466796875,83,
13,,83,0.3940938413143158
14,0.568359375,89,
14,,89,0.3887888491153717
15,0.537750244140625,95,
15,,95,0.3924204409122467
16,0.554779052734375,101,
16,,101,0.3823750913143158
17,0.546142578125,107,
17,,107,0.3799997866153717
18,0.5464935302734375,113,
18,,113,0.377655029296875
19,0.5420684814453125,119,
19,,119,0.3696187436580658
20,0.5392913818359375,125,
20,,125,0.370208740234375
